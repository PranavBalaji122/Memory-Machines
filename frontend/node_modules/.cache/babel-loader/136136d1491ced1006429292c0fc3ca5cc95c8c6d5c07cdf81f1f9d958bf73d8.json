{"ast":null,"code":"var _s = $RefreshSig$();\n/**\n * useAudioCapture Hook\n * Manages Web Audio API and microphone access\n * Handles permissions, audio stream capture, and format conversion\n */\n\nimport { useState, useRef, useCallback, useEffect } from 'react';\n\n/**\n * Custom hook for capturing audio from user's microphone\n * @returns {Object} Hook interface with audio stream and controls\n */\nfunction useAudioCapture() {\n  _s();\n  const [stream, setStream] = useState(null);\n  const [error, setError] = useState(null);\n  const [isCapturing, setIsCapturing] = useState(false);\n  const [permissionState, setPermissionState] = useState('prompt');\n\n  // Refs for audio resources\n  const audioContext = useRef(null);\n  const mediaStream = useRef(null);\n  const audioTracks = useRef([]);\n\n  /**\n   * Check if browser supports getUserMedia\n   */\n  const checkBrowserSupport = () => {\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n      throw new Error('Your browser does not support audio recording. Please use a modern browser.');\n    }\n\n    // Check for secure context (HTTPS)\n    if (window.location.protocol !== 'https:' && window.location.hostname !== 'localhost') {\n      console.warn('Audio capture requires HTTPS in production');\n    }\n  };\n\n  /**\n   * Check microphone permission status\n   */\n  const checkPermission = useCallback(async () => {\n    try {\n      if (navigator.permissions && navigator.permissions.query) {\n        const result = await navigator.permissions.query({\n          name: 'microphone'\n        });\n        setPermissionState(result.state);\n\n        // Listen for permission changes\n        result.addEventListener('change', () => {\n          setPermissionState(result.state);\n        });\n      }\n    } catch (err) {\n      // Permissions API not supported, will handle during getUserMedia\n      console.log('Permissions API not available');\n    }\n  }, []);\n\n  /**\n   * Start capturing audio from microphone\n   * @returns {Promise<MediaStream>} The audio stream\n   */\n  const startCapture = useCallback(async () => {\n    try {\n      setError(null);\n\n      // Check browser support\n      checkBrowserSupport();\n\n      // Check if already capturing\n      if (isCapturing && mediaStream.current) {\n        return mediaStream.current;\n      }\n      setIsCapturing(true);\n\n      // Configure audio constraints for optimal transcription\n      const constraints = {\n        audio: {\n          channelCount: 1,\n          // Mono audio for transcription\n          sampleRate: 16000,\n          // 16kHz sample rate for Deepgram\n          sampleSize: 16,\n          // 16-bit samples\n          echoCancellation: true,\n          // Remove echo\n          noiseSuppression: true,\n          // Remove background noise\n          autoGainControl: true,\n          // Normalize volume\n          deviceId: 'default' // Use default microphone\n        },\n        video: false\n      };\n\n      // Request microphone access\n      console.log('Requesting microphone access...');\n      const audioStream = await navigator.mediaDevices.getUserMedia(constraints);\n\n      // Store the stream and tracks\n      mediaStream.current = audioStream;\n      audioTracks.current = audioStream.getAudioTracks();\n\n      // Log audio track settings\n      if (audioTracks.current.length > 0) {\n        const settings = audioTracks.current[0].getSettings();\n        console.log('Audio track settings:', settings);\n      }\n\n      // Create audio context for processing if needed\n      if (!audioContext.current) {\n        audioContext.current = new (window.AudioContext || window.webkitAudioContext)({\n          sampleRate: 16000,\n          latencyHint: 'interactive'\n        });\n      }\n\n      // Set stream state\n      setStream(audioStream);\n      setPermissionState('granted');\n\n      // Monitor track ended event\n      audioTracks.current.forEach(track => {\n        track.addEventListener('ended', () => {\n          console.log('Audio track ended');\n          stopCapture();\n        });\n      });\n      console.log('Audio capture started successfully');\n      return audioStream;\n    } catch (err) {\n      console.error('Failed to capture audio:', err);\n      setIsCapturing(false);\n\n      // Handle specific error cases\n      let errorMessage = 'Failed to access microphone';\n      if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {\n        errorMessage = 'Microphone access denied. Please grant permission and try again.';\n        setPermissionState('denied');\n      } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {\n        errorMessage = 'No microphone found. Please connect a microphone and try again.';\n      } else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') {\n        errorMessage = 'Microphone is already in use by another application.';\n      } else if (err.name === 'OverconstrainedError' || err.name === 'ConstraintNotSatisfiedError') {\n        errorMessage = 'Your microphone does not support the required settings.';\n      } else if (err.name === 'TypeError') {\n        errorMessage = 'Invalid configuration. Please refresh and try again.';\n      }\n      setError(errorMessage);\n      throw new Error(errorMessage);\n    }\n  }, [isCapturing]);\n\n  /**\n   * Stop capturing audio and clean up resources\n   */\n  const stopCapture = useCallback(() => {\n    console.log('Stopping audio capture...');\n\n    // Stop all audio tracks\n    if (audioTracks.current.length > 0) {\n      audioTracks.current.forEach(track => {\n        track.stop();\n        console.log('Audio track stopped:', track.label);\n      });\n      audioTracks.current = [];\n    }\n\n    // Release the media stream\n    if (mediaStream.current) {\n      mediaStream.current.getTracks().forEach(track => track.stop());\n      mediaStream.current = null;\n    }\n\n    // Close audio context\n    if (audioContext.current) {\n      // Don't close immediately to avoid clicks\n      setTimeout(() => {\n        if (audioContext.current && audioContext.current.state !== 'closed') {\n          audioContext.current.close();\n          audioContext.current = null;\n        }\n      }, 100);\n    }\n\n    // Update state\n    setStream(null);\n    setIsCapturing(false);\n    setError(null);\n    console.log('Audio capture stopped');\n  }, []);\n\n  /**\n   * Get audio level for visualization\n   * @returns {number} Audio level from 0 to 1\n   */\n  const getAudioLevel = useCallback(() => {\n    if (!audioContext.current || !mediaStream.current) {\n      return 0;\n    }\n    try {\n      const analyser = audioContext.current.createAnalyser();\n      const source = audioContext.current.createMediaStreamSource(mediaStream.current);\n      source.connect(analyser);\n      analyser.fftSize = 256;\n      const dataArray = new Uint8Array(analyser.frequencyBinCount);\n      analyser.getByteFrequencyData(dataArray);\n\n      // Calculate average volume\n      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;\n      return average / 255;\n    } catch (err) {\n      return 0;\n    }\n  }, []);\n\n  /**\n   * Check permissions on mount\n   */\n  useEffect(() => {\n    checkPermission();\n  }, [checkPermission]);\n\n  /**\n   * Cleanup on unmount\n   */\n  useEffect(() => {\n    return () => {\n      stopCapture();\n    };\n  }, [stopCapture]);\n  return {\n    stream,\n    isCapturing,\n    permissionState,\n    error,\n    startCapture,\n    stopCapture,\n    getAudioLevel\n  };\n}\n_s(useAudioCapture, \"WC8rTmcEBuKNFGX3WjveceE5m7E=\");\nexport default useAudioCapture;","map":{"version":3,"names":["useState","useRef","useCallback","useEffect","useAudioCapture","_s","stream","setStream","error","setError","isCapturing","setIsCapturing","permissionState","setPermissionState","audioContext","mediaStream","audioTracks","checkBrowserSupport","navigator","mediaDevices","getUserMedia","Error","window","location","protocol","hostname","console","warn","checkPermission","permissions","query","result","name","state","addEventListener","err","log","startCapture","current","constraints","audio","channelCount","sampleRate","sampleSize","echoCancellation","noiseSuppression","autoGainControl","deviceId","video","audioStream","getAudioTracks","length","settings","getSettings","AudioContext","webkitAudioContext","latencyHint","forEach","track","stopCapture","errorMessage","stop","label","getTracks","setTimeout","close","getAudioLevel","analyser","createAnalyser","source","createMediaStreamSource","connect","fftSize","dataArray","Uint8Array","frequencyBinCount","getByteFrequencyData","average","reduce","a","b"],"sources":["/Users/pranavbalaji/Documents/Personal CS Projects/Memory Machines/sentiment-aura/frontend/src/hooks/useAudioCapture.js"],"sourcesContent":["/**\n * useAudioCapture Hook\n * Manages Web Audio API and microphone access\n * Handles permissions, audio stream capture, and format conversion\n */\n\nimport { useState, useRef, useCallback, useEffect } from 'react';\n\n/**\n * Custom hook for capturing audio from user's microphone\n * @returns {Object} Hook interface with audio stream and controls\n */\nfunction useAudioCapture() {\n  const [stream, setStream] = useState(null);\n  const [error, setError] = useState(null);\n  const [isCapturing, setIsCapturing] = useState(false);\n  const [permissionState, setPermissionState] = useState('prompt');\n  \n  // Refs for audio resources\n  const audioContext = useRef(null);\n  const mediaStream = useRef(null);\n  const audioTracks = useRef([]);\n  \n  /**\n   * Check if browser supports getUserMedia\n   */\n  const checkBrowserSupport = () => {\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n      throw new Error('Your browser does not support audio recording. Please use a modern browser.');\n    }\n    \n    // Check for secure context (HTTPS)\n    if (window.location.protocol !== 'https:' && window.location.hostname !== 'localhost') {\n      console.warn('Audio capture requires HTTPS in production');\n    }\n  };\n  \n  /**\n   * Check microphone permission status\n   */\n  const checkPermission = useCallback(async () => {\n    try {\n      if (navigator.permissions && navigator.permissions.query) {\n        const result = await navigator.permissions.query({ name: 'microphone' });\n        setPermissionState(result.state);\n        \n        // Listen for permission changes\n        result.addEventListener('change', () => {\n          setPermissionState(result.state);\n        });\n      }\n    } catch (err) {\n      // Permissions API not supported, will handle during getUserMedia\n      console.log('Permissions API not available');\n    }\n  }, []);\n  \n  /**\n   * Start capturing audio from microphone\n   * @returns {Promise<MediaStream>} The audio stream\n   */\n  const startCapture = useCallback(async () => {\n    try {\n      setError(null);\n      \n      // Check browser support\n      checkBrowserSupport();\n      \n      // Check if already capturing\n      if (isCapturing && mediaStream.current) {\n        return mediaStream.current;\n      }\n      \n      setIsCapturing(true);\n      \n      // Configure audio constraints for optimal transcription\n      const constraints = {\n        audio: {\n          channelCount: 1,           // Mono audio for transcription\n          sampleRate: 16000,         // 16kHz sample rate for Deepgram\n          sampleSize: 16,            // 16-bit samples\n          echoCancellation: true,    // Remove echo\n          noiseSuppression: true,    // Remove background noise\n          autoGainControl: true,     // Normalize volume\n          deviceId: 'default'        // Use default microphone\n        },\n        video: false\n      };\n      \n      // Request microphone access\n      console.log('Requesting microphone access...');\n      const audioStream = await navigator.mediaDevices.getUserMedia(constraints);\n      \n      // Store the stream and tracks\n      mediaStream.current = audioStream;\n      audioTracks.current = audioStream.getAudioTracks();\n      \n      // Log audio track settings\n      if (audioTracks.current.length > 0) {\n        const settings = audioTracks.current[0].getSettings();\n        console.log('Audio track settings:', settings);\n      }\n      \n      // Create audio context for processing if needed\n      if (!audioContext.current) {\n        audioContext.current = new (window.AudioContext || window.webkitAudioContext)({\n          sampleRate: 16000,\n          latencyHint: 'interactive'\n        });\n      }\n      \n      // Set stream state\n      setStream(audioStream);\n      setPermissionState('granted');\n      \n      // Monitor track ended event\n      audioTracks.current.forEach(track => {\n        track.addEventListener('ended', () => {\n          console.log('Audio track ended');\n          stopCapture();\n        });\n      });\n      \n      console.log('Audio capture started successfully');\n      return audioStream;\n      \n    } catch (err) {\n      console.error('Failed to capture audio:', err);\n      setIsCapturing(false);\n      \n      // Handle specific error cases\n      let errorMessage = 'Failed to access microphone';\n      \n      if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {\n        errorMessage = 'Microphone access denied. Please grant permission and try again.';\n        setPermissionState('denied');\n      } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {\n        errorMessage = 'No microphone found. Please connect a microphone and try again.';\n      } else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') {\n        errorMessage = 'Microphone is already in use by another application.';\n      } else if (err.name === 'OverconstrainedError' || err.name === 'ConstraintNotSatisfiedError') {\n        errorMessage = 'Your microphone does not support the required settings.';\n      } else if (err.name === 'TypeError') {\n        errorMessage = 'Invalid configuration. Please refresh and try again.';\n      }\n      \n      setError(errorMessage);\n      throw new Error(errorMessage);\n    }\n  }, [isCapturing]);\n  \n  /**\n   * Stop capturing audio and clean up resources\n   */\n  const stopCapture = useCallback(() => {\n    console.log('Stopping audio capture...');\n    \n    // Stop all audio tracks\n    if (audioTracks.current.length > 0) {\n      audioTracks.current.forEach(track => {\n        track.stop();\n        console.log('Audio track stopped:', track.label);\n      });\n      audioTracks.current = [];\n    }\n    \n    // Release the media stream\n    if (mediaStream.current) {\n      mediaStream.current.getTracks().forEach(track => track.stop());\n      mediaStream.current = null;\n    }\n    \n    // Close audio context\n    if (audioContext.current) {\n      // Don't close immediately to avoid clicks\n      setTimeout(() => {\n        if (audioContext.current && audioContext.current.state !== 'closed') {\n          audioContext.current.close();\n          audioContext.current = null;\n        }\n      }, 100);\n    }\n    \n    // Update state\n    setStream(null);\n    setIsCapturing(false);\n    setError(null);\n    \n    console.log('Audio capture stopped');\n  }, []);\n  \n  /**\n   * Get audio level for visualization\n   * @returns {number} Audio level from 0 to 1\n   */\n  const getAudioLevel = useCallback(() => {\n    if (!audioContext.current || !mediaStream.current) {\n      return 0;\n    }\n    \n    try {\n      const analyser = audioContext.current.createAnalyser();\n      const source = audioContext.current.createMediaStreamSource(mediaStream.current);\n      source.connect(analyser);\n      \n      analyser.fftSize = 256;\n      const dataArray = new Uint8Array(analyser.frequencyBinCount);\n      analyser.getByteFrequencyData(dataArray);\n      \n      // Calculate average volume\n      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;\n      return average / 255;\n    } catch (err) {\n      return 0;\n    }\n  }, []);\n  \n  /**\n   * Check permissions on mount\n   */\n  useEffect(() => {\n    checkPermission();\n  }, [checkPermission]);\n  \n  /**\n   * Cleanup on unmount\n   */\n  useEffect(() => {\n    return () => {\n      stopCapture();\n    };\n  }, [stopCapture]);\n  \n  return {\n    stream,\n    isCapturing,\n    permissionState,\n    error,\n    startCapture,\n    stopCapture,\n    getAudioLevel\n  };\n}\n\nexport default useAudioCapture;\n"],"mappings":";AAAA;AACA;AACA;AACA;AACA;;AAEA,SAASA,QAAQ,EAAEC,MAAM,EAAEC,WAAW,EAAEC,SAAS,QAAQ,OAAO;;AAEhE;AACA;AACA;AACA;AACA,SAASC,eAAeA,CAAA,EAAG;EAAAC,EAAA;EACzB,MAAM,CAACC,MAAM,EAAEC,SAAS,CAAC,GAAGP,QAAQ,CAAC,IAAI,CAAC;EAC1C,MAAM,CAACQ,KAAK,EAAEC,QAAQ,CAAC,GAAGT,QAAQ,CAAC,IAAI,CAAC;EACxC,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACY,eAAe,EAAEC,kBAAkB,CAAC,GAAGb,QAAQ,CAAC,QAAQ,CAAC;;EAEhE;EACA,MAAMc,YAAY,GAAGb,MAAM,CAAC,IAAI,CAAC;EACjC,MAAMc,WAAW,GAAGd,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMe,WAAW,GAAGf,MAAM,CAAC,EAAE,CAAC;;EAE9B;AACF;AACA;EACE,MAAMgB,mBAAmB,GAAGA,CAAA,KAAM;IAChC,IAAI,CAACC,SAAS,CAACC,YAAY,IAAI,CAACD,SAAS,CAACC,YAAY,CAACC,YAAY,EAAE;MACnE,MAAM,IAAIC,KAAK,CAAC,6EAA6E,CAAC;IAChG;;IAEA;IACA,IAAIC,MAAM,CAACC,QAAQ,CAACC,QAAQ,KAAK,QAAQ,IAAIF,MAAM,CAACC,QAAQ,CAACE,QAAQ,KAAK,WAAW,EAAE;MACrFC,OAAO,CAACC,IAAI,CAAC,4CAA4C,CAAC;IAC5D;EACF,CAAC;;EAED;AACF;AACA;EACE,MAAMC,eAAe,GAAG1B,WAAW,CAAC,YAAY;IAC9C,IAAI;MACF,IAAIgB,SAAS,CAACW,WAAW,IAAIX,SAAS,CAACW,WAAW,CAACC,KAAK,EAAE;QACxD,MAAMC,MAAM,GAAG,MAAMb,SAAS,CAACW,WAAW,CAACC,KAAK,CAAC;UAAEE,IAAI,EAAE;QAAa,CAAC,CAAC;QACxEnB,kBAAkB,CAACkB,MAAM,CAACE,KAAK,CAAC;;QAEhC;QACAF,MAAM,CAACG,gBAAgB,CAAC,QAAQ,EAAE,MAAM;UACtCrB,kBAAkB,CAACkB,MAAM,CAACE,KAAK,CAAC;QAClC,CAAC,CAAC;MACJ;IACF,CAAC,CAAC,OAAOE,GAAG,EAAE;MACZ;MACAT,OAAO,CAACU,GAAG,CAAC,+BAA+B,CAAC;IAC9C;EACF,CAAC,EAAE,EAAE,CAAC;;EAEN;AACF;AACA;AACA;EACE,MAAMC,YAAY,GAAGnC,WAAW,CAAC,YAAY;IAC3C,IAAI;MACFO,QAAQ,CAAC,IAAI,CAAC;;MAEd;MACAQ,mBAAmB,CAAC,CAAC;;MAErB;MACA,IAAIP,WAAW,IAAIK,WAAW,CAACuB,OAAO,EAAE;QACtC,OAAOvB,WAAW,CAACuB,OAAO;MAC5B;MAEA3B,cAAc,CAAC,IAAI,CAAC;;MAEpB;MACA,MAAM4B,WAAW,GAAG;QAClBC,KAAK,EAAE;UACLC,YAAY,EAAE,CAAC;UAAY;UAC3BC,UAAU,EAAE,KAAK;UAAU;UAC3BC,UAAU,EAAE,EAAE;UAAa;UAC3BC,gBAAgB,EAAE,IAAI;UAAK;UAC3BC,gBAAgB,EAAE,IAAI;UAAK;UAC3BC,eAAe,EAAE,IAAI;UAAM;UAC3BC,QAAQ,EAAE,SAAS,CAAQ;QAC7B,CAAC;QACDC,KAAK,EAAE;MACT,CAAC;;MAED;MACAtB,OAAO,CAACU,GAAG,CAAC,iCAAiC,CAAC;MAC9C,MAAMa,WAAW,GAAG,MAAM/B,SAAS,CAACC,YAAY,CAACC,YAAY,CAACmB,WAAW,CAAC;;MAE1E;MACAxB,WAAW,CAACuB,OAAO,GAAGW,WAAW;MACjCjC,WAAW,CAACsB,OAAO,GAAGW,WAAW,CAACC,cAAc,CAAC,CAAC;;MAElD;MACA,IAAIlC,WAAW,CAACsB,OAAO,CAACa,MAAM,GAAG,CAAC,EAAE;QAClC,MAAMC,QAAQ,GAAGpC,WAAW,CAACsB,OAAO,CAAC,CAAC,CAAC,CAACe,WAAW,CAAC,CAAC;QACrD3B,OAAO,CAACU,GAAG,CAAC,uBAAuB,EAAEgB,QAAQ,CAAC;MAChD;;MAEA;MACA,IAAI,CAACtC,YAAY,CAACwB,OAAO,EAAE;QACzBxB,YAAY,CAACwB,OAAO,GAAG,KAAKhB,MAAM,CAACgC,YAAY,IAAIhC,MAAM,CAACiC,kBAAkB,EAAE;UAC5Eb,UAAU,EAAE,KAAK;UACjBc,WAAW,EAAE;QACf,CAAC,CAAC;MACJ;;MAEA;MACAjD,SAAS,CAAC0C,WAAW,CAAC;MACtBpC,kBAAkB,CAAC,SAAS,CAAC;;MAE7B;MACAG,WAAW,CAACsB,OAAO,CAACmB,OAAO,CAACC,KAAK,IAAI;QACnCA,KAAK,CAACxB,gBAAgB,CAAC,OAAO,EAAE,MAAM;UACpCR,OAAO,CAACU,GAAG,CAAC,mBAAmB,CAAC;UAChCuB,WAAW,CAAC,CAAC;QACf,CAAC,CAAC;MACJ,CAAC,CAAC;MAEFjC,OAAO,CAACU,GAAG,CAAC,oCAAoC,CAAC;MACjD,OAAOa,WAAW;IAEpB,CAAC,CAAC,OAAOd,GAAG,EAAE;MACZT,OAAO,CAAClB,KAAK,CAAC,0BAA0B,EAAE2B,GAAG,CAAC;MAC9CxB,cAAc,CAAC,KAAK,CAAC;;MAErB;MACA,IAAIiD,YAAY,GAAG,6BAA6B;MAEhD,IAAIzB,GAAG,CAACH,IAAI,KAAK,iBAAiB,IAAIG,GAAG,CAACH,IAAI,KAAK,uBAAuB,EAAE;QAC1E4B,YAAY,GAAG,kEAAkE;QACjF/C,kBAAkB,CAAC,QAAQ,CAAC;MAC9B,CAAC,MAAM,IAAIsB,GAAG,CAACH,IAAI,KAAK,eAAe,IAAIG,GAAG,CAACH,IAAI,KAAK,sBAAsB,EAAE;QAC9E4B,YAAY,GAAG,iEAAiE;MAClF,CAAC,MAAM,IAAIzB,GAAG,CAACH,IAAI,KAAK,kBAAkB,IAAIG,GAAG,CAACH,IAAI,KAAK,iBAAiB,EAAE;QAC5E4B,YAAY,GAAG,sDAAsD;MACvE,CAAC,MAAM,IAAIzB,GAAG,CAACH,IAAI,KAAK,sBAAsB,IAAIG,GAAG,CAACH,IAAI,KAAK,6BAA6B,EAAE;QAC5F4B,YAAY,GAAG,yDAAyD;MAC1E,CAAC,MAAM,IAAIzB,GAAG,CAACH,IAAI,KAAK,WAAW,EAAE;QACnC4B,YAAY,GAAG,sDAAsD;MACvE;MAEAnD,QAAQ,CAACmD,YAAY,CAAC;MACtB,MAAM,IAAIvC,KAAK,CAACuC,YAAY,CAAC;IAC/B;EACF,CAAC,EAAE,CAAClD,WAAW,CAAC,CAAC;;EAEjB;AACF;AACA;EACE,MAAMiD,WAAW,GAAGzD,WAAW,CAAC,MAAM;IACpCwB,OAAO,CAACU,GAAG,CAAC,2BAA2B,CAAC;;IAExC;IACA,IAAIpB,WAAW,CAACsB,OAAO,CAACa,MAAM,GAAG,CAAC,EAAE;MAClCnC,WAAW,CAACsB,OAAO,CAACmB,OAAO,CAACC,KAAK,IAAI;QACnCA,KAAK,CAACG,IAAI,CAAC,CAAC;QACZnC,OAAO,CAACU,GAAG,CAAC,sBAAsB,EAAEsB,KAAK,CAACI,KAAK,CAAC;MAClD,CAAC,CAAC;MACF9C,WAAW,CAACsB,OAAO,GAAG,EAAE;IAC1B;;IAEA;IACA,IAAIvB,WAAW,CAACuB,OAAO,EAAE;MACvBvB,WAAW,CAACuB,OAAO,CAACyB,SAAS,CAAC,CAAC,CAACN,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACG,IAAI,CAAC,CAAC,CAAC;MAC9D9C,WAAW,CAACuB,OAAO,GAAG,IAAI;IAC5B;;IAEA;IACA,IAAIxB,YAAY,CAACwB,OAAO,EAAE;MACxB;MACA0B,UAAU,CAAC,MAAM;QACf,IAAIlD,YAAY,CAACwB,OAAO,IAAIxB,YAAY,CAACwB,OAAO,CAACL,KAAK,KAAK,QAAQ,EAAE;UACnEnB,YAAY,CAACwB,OAAO,CAAC2B,KAAK,CAAC,CAAC;UAC5BnD,YAAY,CAACwB,OAAO,GAAG,IAAI;QAC7B;MACF,CAAC,EAAE,GAAG,CAAC;IACT;;IAEA;IACA/B,SAAS,CAAC,IAAI,CAAC;IACfI,cAAc,CAAC,KAAK,CAAC;IACrBF,QAAQ,CAAC,IAAI,CAAC;IAEdiB,OAAO,CAACU,GAAG,CAAC,uBAAuB,CAAC;EACtC,CAAC,EAAE,EAAE,CAAC;;EAEN;AACF;AACA;AACA;EACE,MAAM8B,aAAa,GAAGhE,WAAW,CAAC,MAAM;IACtC,IAAI,CAACY,YAAY,CAACwB,OAAO,IAAI,CAACvB,WAAW,CAACuB,OAAO,EAAE;MACjD,OAAO,CAAC;IACV;IAEA,IAAI;MACF,MAAM6B,QAAQ,GAAGrD,YAAY,CAACwB,OAAO,CAAC8B,cAAc,CAAC,CAAC;MACtD,MAAMC,MAAM,GAAGvD,YAAY,CAACwB,OAAO,CAACgC,uBAAuB,CAACvD,WAAW,CAACuB,OAAO,CAAC;MAChF+B,MAAM,CAACE,OAAO,CAACJ,QAAQ,CAAC;MAExBA,QAAQ,CAACK,OAAO,GAAG,GAAG;MACtB,MAAMC,SAAS,GAAG,IAAIC,UAAU,CAACP,QAAQ,CAACQ,iBAAiB,CAAC;MAC5DR,QAAQ,CAACS,oBAAoB,CAACH,SAAS,CAAC;;MAExC;MACA,MAAMI,OAAO,GAAGJ,SAAS,CAACK,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,CAAC,GAAGP,SAAS,CAACtB,MAAM;MACpE,OAAO0B,OAAO,GAAG,GAAG;IACtB,CAAC,CAAC,OAAO1C,GAAG,EAAE;MACZ,OAAO,CAAC;IACV;EACF,CAAC,EAAE,EAAE,CAAC;;EAEN;AACF;AACA;EACEhC,SAAS,CAAC,MAAM;IACdyB,eAAe,CAAC,CAAC;EACnB,CAAC,EAAE,CAACA,eAAe,CAAC,CAAC;;EAErB;AACF;AACA;EACEzB,SAAS,CAAC,MAAM;IACd,OAAO,MAAM;MACXwD,WAAW,CAAC,CAAC;IACf,CAAC;EACH,CAAC,EAAE,CAACA,WAAW,CAAC,CAAC;EAEjB,OAAO;IACLrD,MAAM;IACNI,WAAW;IACXE,eAAe;IACfJ,KAAK;IACL6B,YAAY;IACZsB,WAAW;IACXO;EACF,CAAC;AACH;AAAC7D,EAAA,CAtOQD,eAAe;AAwOxB,eAAeA,eAAe","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}